{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd11448c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "!pip install imutils wandb\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209ee376",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import os\n",
    "import shutil\n",
    "import itertools\n",
    "import imutils\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "from plotly import tools\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D,BatchNormalization, MaxPooling2D,Dropout,Flatten,Dense, Activation\n",
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import keras_tuner as kt\n",
    "\n",
    "sns.set_style('darkgrid')\n",
    "%matplotlib inline\n",
    "init_notebook_mode(connected=True)\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2bc7e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "!apt-get install tree\n",
    "clear_output()\n",
    "# create new folders\n",
    "!mkdir TRAIN TEST VAL TRAIN/YES TRAIN/NO TEST/YES TEST/NO VAL/YES VAL/NO\n",
    "!tree -d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d61950",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_PATH = '../input/brain-mri-images-for-brain-tumor-detection/brain_tumor_dataset/'\n",
    "\n",
    "# split the data by train/val/test\n",
    "for CLASS in os.listdir(IMG_PATH):\n",
    "    if not CLASS.startswith('.'):\n",
    "        IMG_NUM = len(os.listdir(IMG_PATH + CLASS))\n",
    "        for (n, FILE_NAME) in enumerate(os.listdir(IMG_PATH + CLASS)):\n",
    "            img = IMG_PATH + CLASS + '/' + FILE_NAME\n",
    "            if n<5:\n",
    "                shutil.copy(img, 'TEST/' + CLASS.upper() + '/' + FILE_NAME)\n",
    "            elif n<0.8*IMG_NUM:\n",
    "                shutil.copy(img, 'TRAIN/' + CLASS.upper() + '/' + FILE_NAME)\n",
    "            else:\n",
    "                shutil.copy(img, 'VAL/' + CLASS.upper() + '/' + FILE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc347fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(dir_path, img_size=(100,100)):\n",
    "    X = []\n",
    "    y = []\n",
    "    i=0\n",
    "    labels = dict()\n",
    "    for path in tqdm(sorted(os.listdir(dir_path))):\n",
    "        if not path.startswith('.'):\n",
    "            labels[i] = path\n",
    "            for file in os.listdir(dir_path + path):\n",
    "                if not file.startswith('.'):\n",
    "                    img = cv2.imread(dir_path + path + '/' + file)\n",
    "                    X.append(img)\n",
    "                    y.append(i)\n",
    "            i += 1\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    print(f'{len(X)} images loaded from {dir_path} directory.')\n",
    "    return X, y, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0f9fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DIR = 'TRAIN/'\n",
    "TEST_DIR = 'TEST/'\n",
    "VAL_DIR = 'VAL/'\n",
    "IMG_SIZE = (224,224)\n",
    "\n",
    "# use predefined function to load the image data into workspace\n",
    "X_train, y_train, labels = load_data(TRAIN_DIR, IMG_SIZE)\n",
    "X_test, y_test, _  = load_data(TEST_DIR, IMG_SIZE)\n",
    "X_val, y_val, _ = load_data(VAL_DIR, IMG_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615a8627",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = dict()\n",
    "y[0] = []\n",
    "y[1] = []\n",
    "for set_name in (y_train, y_val, y_test):\n",
    "    y[0].append(np.sum(set_name==0))\n",
    "    y[1].append(np.sum(set_name==1))\n",
    "trace0 = go.Bar(\n",
    "    x=['Train Set', 'Validation Set', 'Test Set'],\n",
    "    y=y[0],\n",
    "    name='No',\n",
    "    marker=dict(color='#33cc33'),\n",
    "    opacity=0.7)\n",
    "trace1 = go.Bar(\n",
    "    x=['Train Set', 'Validation Set', 'Test Set'],\n",
    "    y=y[1],\n",
    "    name='Yes',\n",
    "    marker=dict(color='#ff3300'),\n",
    "    opacity=0.7)\n",
    "\n",
    "data = [trace0, trace1]\n",
    "layout = go.Layout(\n",
    "    title='Count of classes in each set',\n",
    "    xaxis={'title':'Set'},\n",
    "    yaxis={'title':'Count'}\n",
    ")\n",
    "fig = go.Figure(data,layout)\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd38cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_samples(X,y,labels_dict, n=50):\n",
    "    \"\"\"\n",
    "        Create a gridplot for desired number of images (n) from specified set\n",
    "    \"\"\" \n",
    "    for index in range(len(labels_dict)):\n",
    "        imgs = X[np.argwhere(y==index)][:n]\n",
    "        j = 10\n",
    "        i = int(n/j)\n",
    "        \n",
    "        plt.figure(figsize=(15,6))\n",
    "        c = 1\n",
    "        for img in imgs:\n",
    "            plt.subplot(i,j,c)\n",
    "            plt.imshow(img[0])\n",
    "            \n",
    "            plt.xticks([])\n",
    "            plt.yticks([])\n",
    "            c += 1\n",
    "        plt.suptitle('Tumor: {}'.format(labels_dict[index]))\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdea6d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_samples(X_train, y_train, labels, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f670800d",
   "metadata": {},
   "outputs": [],
   "source": [
    "RATIO_LIST = []\n",
    "for set in (X_train, X_test, X_val):\n",
    "    for img in set:\n",
    "        RATIO_LIST.append(img.shape[1]/img.shape[0])\n",
    "        \n",
    "plt.hist(RATIO_LIST)\n",
    "plt.title('Distribution of Image Ratios')\n",
    "plt.xlabel('Ratio Value')\n",
    "plt.ylabel('Count')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07c563b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_imgs(set_name, add_pixels_value=0):\n",
    "    \"\"\"\n",
    "    Finds the extreme points on the image and crops the rectangular out of them\n",
    "    \"\"\"\n",
    "    set_new = []\n",
    "    for img in set_name:\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "        gray = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "\n",
    "        # threshold the image, then perform a series of erosions +\n",
    "        # dilations to remove any small regions of noise\n",
    "        thresh = cv2.threshold(gray, 45, 255, cv2.THRESH_BINARY)[1]\n",
    "        thresh = cv2.erode(thresh, None, iterations=2)\n",
    "        thresh = cv2.dilate(thresh, None, iterations=2)\n",
    "\n",
    "        # find contours in thresholded image, then grab the largest one\n",
    "        cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        cnts = imutils.grab_contours(cnts)\n",
    "        c = max(cnts, key=cv2.contourArea)\n",
    "\n",
    "        # find the extreme points\n",
    "        extLeft = tuple(c[c[:, :, 0].argmin()][0])\n",
    "        extRight = tuple(c[c[:, :, 0].argmax()][0])\n",
    "        extTop = tuple(c[c[:, :, 1].argmin()][0])\n",
    "        extBot = tuple(c[c[:, :, 1].argmax()][0])\n",
    "\n",
    "        ADD_PIXELS = add_pixels_value\n",
    "        new_img = img[extTop[1]-ADD_PIXELS:extBot[1]+ADD_PIXELS, extLeft[0]-ADD_PIXELS:extRight[0]+ADD_PIXELS].copy()\n",
    "        set_new.append(new_img)\n",
    "\n",
    "    return np.array(set_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea18dad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('../input/brain-mri-images-for-brain-tumor-detection/brain_tumor_dataset/yes/Y108.jpg')\n",
    "img = cv2.resize(\n",
    "            img,\n",
    "            dsize=IMG_SIZE,\n",
    "            interpolation=cv2.INTER_CUBIC\n",
    "        )\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "gray = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "\n",
    "# threshold the image, then perform a series of erosions +\n",
    "# dilations to remove any small regions of noise\n",
    "thresh = cv2.threshold(gray, 45, 255, cv2.THRESH_BINARY)[1]\n",
    "thresh = cv2.erode(thresh, None, iterations=2)\n",
    "thresh = cv2.dilate(thresh, None, iterations=2)\n",
    "\n",
    "# find contours in thresholded image, then grab the largest one\n",
    "cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "img = cv2.imread('../input/brain-mri-images-for-brain-tumor-detection/brain_tumor_dataset/yes/Y108.jpg')\n",
    "img = cv2.resize(\n",
    "            img,\n",
    "            dsize=IMG_SIZE,\n",
    "            interpolation=cv2.INTER_CUBIC\n",
    "        )\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "gray = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "\n",
    "# threshold the image, then perform a series of erosions +\n",
    "# dilations to remove any small regions of noise\n",
    "thresh = cv2.threshold(gray, 45, 255, cv2.THRESH_BINARY)[1]\n",
    "thresh = cv2.erode(thresh, None, iterations=2)\n",
    "thresh = cv2.dilate(thresh, None, iterations=2)\n",
    "\n",
    "# find contours in thresholded image, then grab the largest one\n",
    "cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "cnts = imutils.grab_contours(cnts)\n",
    "c = max(cnts, key=cv2.contourArea)\n",
    "\n",
    "# find the extreme points\n",
    "extLeft = tuple(c[c[:, :, 0].argmin()][0])\n",
    "extRight = tuple(c[c[:, :, 0].argmax()][0])\n",
    "extTop = tuple(c[c[:, :, 1].argmin()][0])\n",
    "extBot = tuple(c[c[:, :, 1].argmax()][0])\n",
    "\n",
    "# add contour on the image\n",
    "img_cnt = cv2.drawContours(img.copy(), [c], -1, (0, 255, 255), 4)\n",
    "\n",
    "# add extreme points\n",
    "img_pnt = cv2.circle(img_cnt.copy(), extLeft, 8, (0, 0, 255), -1)\n",
    "img_pnt = cv2.circle(img_pnt, extRight, 8, (0, 255, 0), -1)\n",
    "img_pnt = cv2.circle(img_pnt, extTop, 8, (255, 0, 0), -1)\n",
    "img_pnt = cv2.circle(img_pnt, extBot, 8, (255, 255, 0), -1)\n",
    "\n",
    "# crop\n",
    "ADD_PIXELS = 0\n",
    "new_img = img[extTop[1]-ADD_PIXELS:extBot[1]+ADD_PIXELS, extLeft[0]-ADD_PIXELS:extRight[0]+ADD_PIXELS].copy()\n",
    "plt.figure(figsize=(15,6))\n",
    "plt.subplot(141)\n",
    "plt.imshow(img)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.title('Step 1. Get the original image')\n",
    "plt.subplot(142)\n",
    "plt.imshow(img_cnt)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.title('Step 2. Find the biggest contour')\n",
    "plt.subplot(143)\n",
    "plt.imshow(img_pnt)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.title('Step 3. Find the extreme points')\n",
    "plt.subplot(144)\n",
    "plt.imshow(new_img)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.title('Step 4. Crop the image')\n",
    "\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db963d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply this for each set\n",
    "X_train_crop = crop_imgs(set_name=X_train)\n",
    "X_val_crop = crop_imgs(set_name=X_val)\n",
    "X_test_crop = crop_imgs(set_name=X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb7b60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_samples(X_train_crop, y_train, labels, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c30ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_new_images(x_set, y_set, folder_name):\n",
    "    i = 0\n",
    "    for (img, imclass) in zip(x_set, y_set):\n",
    "        if imclass == 0:\n",
    "            cv2.imwrite(folder_name+'NO/'+str(i)+'.jpg', img)\n",
    "        else:\n",
    "            cv2.imwrite(folder_name+'YES/'+str(i)+'.jpg', img)\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee88c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving new images to the folder\n",
    "!mkdir TRAIN_CROP TEST_CROP VAL_CROP TRAIN_CROP/YES TRAIN_CROP/NO TEST_CROP/YES TEST_CROP/NO VAL_CROP/YES VAL_CROP/NO\n",
    "\n",
    "save_new_images(X_train_crop, y_train, folder_name='TRAIN_CROP/')\n",
    "save_new_images(X_val_crop, y_val, folder_name='VAL_CROP/')\n",
    "save_new_images(X_test_crop, y_test, folder_name='TEST_CROP/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9194bd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_imgs(set_name, img_size):\n",
    "    \"\"\"\n",
    "    Resize and apply VGG-15 preprocessing\n",
    "    \"\"\"\n",
    "    set_new = []\n",
    "    for img in set_name:\n",
    "        img = cv2.resize(\n",
    "            img,\n",
    "            dsize=img_size,\n",
    "            interpolation=cv2.INTER_CUBIC\n",
    "        )\n",
    "        set_new.append(preprocess_input(img))\n",
    "    return np.array(set_new)\n",
    "X_train_prep = preprocess_imgs(set_name=X_train_crop, img_size=IMG_SIZE)\n",
    "X_test_prep = preprocess_imgs(set_name=X_test_crop, img_size=IMG_SIZE)\n",
    "X_val_prep = preprocess_imgs(set_name=X_val_crop, img_size=IMG_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76ce04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_samples(X_train_prep,y_train,labels,30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
